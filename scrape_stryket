# -*- coding: utf-8 -*-
# scrape_stryket.py – läser kupongen från stryketanalysen.se/stryktipset/

from typing import Dict, Any, List
import re
import requests
from bs4 import BeautifulSoup

HEADERS = {
    "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/124.0 Safari/537.36"),
    "Accept-Language": "sv-SE,sv;q=0.9,en-US;q=0.8,en;q=0.7",
}

def _to_float(s: str):
    s = s.strip().replace(",", ".")
    try:
        return float(s)
    except Exception:
        return None

def _to_int(s: str):
    s = re.sub(r"[^\d]", "", s)
    try:
        return int(s)
    except Exception:
        return None

def _parse(html: str) -> List[Dict[str, Any]]:
    soup = BeautifulSoup(html, "html.parser")
    rows: List[Dict[str, Any]] = []

    # Vanligast: sidan har en tabell/lista med 13 matcher.
    # Vi letar efter rader som innehåller två lagnamn, och ev. odds/procent.
    # Selektorerna nedan är toleranta – funkar för både tabell och div-lista.

    # 1) Tabellrad-fall
    tr_candidates = soup.select("table tr")
    for i, tr in enumerate(tr_candidates, start=1):
        txt = " ".join(tr.stripped_strings)
        # Ex: "1 Halmstad - Sirius 1 3.30 X 3.70 2 2.14"
        m = re.search(r"([A-Za-zÅÄÖåäö0-9\.\-’'& ]+?)\s*-\s*([A-Za-zÅÄÖåäö0-9\.\-’'& ]+)", txt)
        if not m:
            continue
        home, away = m.group(1).strip(), m.group(2).strip()

        # odds (tre tal) om de finns på samma rad
        odds = re.findall(r"(\d+(?:[.,]\d+)?)", txt)
        o1 = ox = o2 = None
        if len(odds) >= 3:
            o1, ox, o2 = map(_to_float, odds[:3])

        # svenska folket-procent (tre heltal med %)
        folk = re.findall(r"(\d{1,2})\s*%", txt)
        f1 = fx = f2 = None
        if len(folk) >= 3:
            f1, fx, f2 = map(_to_int, folk[:3])

        rows.append({
            "matchnr": len(rows) + 1,
            "hemmalag": home, "bortalag": away,
            "odds_1": o1, "odds_x": ox, "odds_2": o2,
            "folk_1": f1, "folk_x": fx, "folk_2": f2,
        })

    # 2) Om inget hittades i tabell – prova generiska list-block
    if not rows:
        blocks = soup.select("li, .match, .match-row, .kupong-row, .game-row, article")
        for blk in blocks:
            txt = " ".join(blk.stripped_strings)
            m = re.search(r"([A-Za-zÅÄÖåäö0-9\.\-’'& ]+?)\s*-\s*([A-Za-zÅÄÖåäö0-9\.\-’'& ]+)", txt)
            if not m:
                continue
            home, away = m.group(1).strip(), m.group(2).strip()
            odds = re.findall(r"(\d+(?:[.,]\d+)?)", txt)
            o1 = ox = o2 = None
            if len(odds) >= 3:
                o1, ox, o2 = map(_to_float, odds[:3])
            folk = re.findall(r"(\d{1,2})\s*%", txt)
            f1 = fx = f2 = None
            if len(folk) >= 3:
                f1, fx, f2 = map(_to_int, folk[:3])

            rows.append({
                "matchnr": len(rows) + 1,
                "hemmalag": home, "bortalag": away,
                "odds_1": o1, "odds_x": ox, "odds_2": o2,
                "folk_1": f1, "folk_x": fx, "folk_2": f2,
            })

    # Deduplicera & klipp till 13
    seen = set()
    unique = []
    for r in rows:
        key = (r["hemmalag"], r["bortalag"], r["odds_1"], r["odds_x"], r["odds_2"], r["folk_1"], r["folk_x"], r["folk_2"])
        if key in seen:
            continue
        seen.add(key)
        unique.append(r)
    for i, r in enumerate(unique[:13], start=1):
        r["matchnr"] = i
    return unique[:13]

def fetch_stryket(url: str) -> Dict[str, Any]:
    r = requests.get(url, headers=HEADERS, timeout=30)
    if r.status_code >= 400:
        return {"error": f"HTTP {r.status_code}"}
    rows = _parse(r.text)
    if not rows:
        return {"error": "Hittade inga matcher på sidan."}
    return {"results": rows}
